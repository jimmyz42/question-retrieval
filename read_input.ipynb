{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import Tensor\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_tokenized(text_tokenized_file, truncate_length=100):\n",
    "    # returns a dictionary of {question_id : (title, body)} key-value pairs\n",
    "    print('read corpus', text_tokenized_file)\n",
    "    question_id_to_title_body_tuple = {}\n",
    "    for line in open(text_tokenized_file, 'r'):\n",
    "        question_id, title, body = line.lower().split('\\t')\n",
    "        title = title.split()[:truncate_length]\n",
    "        body = body.split()[:truncate_length]\n",
    "        if len(title) == 0:\n",
    "            title = ['title']\n",
    "        if len(body) == 0:\n",
    "            body = ['body']\n",
    "        question_id_to_title_body_tuple[question_id] = (title, body)\n",
    "    return question_id_to_title_body_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_ids(train_file, test_subset):\n",
    "    # returns list of (question_id, positive_id, [negative_id, ...]) tuples\n",
    "    # where all ids are strings\n",
    "    train_id_instances = []\n",
    "    i = 0\n",
    "    for line in open(train_file):\n",
    "        qid, positive_ids, negative_ids = line.split('\\t')\n",
    "        negative_ids = negative_ids.split()\n",
    "        for positive_id in positive_ids.split():\n",
    "            train_id_instances.append((qid, positive_id, negative_ids))\n",
    "            i += 1\n",
    "        if (test_subset is not None) and i > test_subset:\n",
    "            break\n",
    "    return train_id_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ubuntu_eval_ids(eval_file, test_subset):\n",
    "    # returns list of (question_id, candidate_ids, labels, bm25scores) tuples\n",
    "    # where all ids are strings, and labels is a list of binary positive/negative for each candidate in candidate_ids\n",
    "    eval_id_instances = []\n",
    "    i = 0\n",
    "    for line in open(eval_file):\n",
    "        qid, positive_ids, candidate_ids, bm25scores = line.split('\\t')\n",
    "        positive_ids_set = set(positive_ids.split())\n",
    "        candidate_ids = candidate_ids.split()\n",
    "        bm25scores = [float(score) for score in bm25scores.split()]\n",
    "        if len(positive_ids_set) == 0:\n",
    "            continue\n",
    "        labels = [1 if cid in positive_ids_set else 0 for cid in candidate_ids]\n",
    "        #assert(sum(labels)==len(positive_ids_set))\n",
    "        eval_id_instances.append((qid, candidate_ids, labels, bm25scores))\n",
    "        i += 1\n",
    "        if (test_subset is not None) and i > test_subset:\n",
    "            break\n",
    "    return eval_id_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_android_eval_ids(pos_file_name, neg_file_name, test_subset=None):\n",
    "    # returns list of (question_id, candidate_ids, labels) tuples\n",
    "    # where all ids are strings, and labels is a list of binary positive/negative for each candidate in candidate_ids \n",
    "    \n",
    "    eval_id_instances = []\n",
    "    pos_file = open(pos_file_name)\n",
    "    neg_file = open(neg_file_name)\n",
    "    i = 0\n",
    "    while True:\n",
    "        # reads in one sample\n",
    "        pos_file_line = pos_file.readline()\n",
    "        if len(pos_file_line) == 0:\n",
    "            break\n",
    "        query, pos = pos_file_line.split()\n",
    "        queries = [query]\n",
    "        candidates = [pos]\n",
    "        labels = [1]\n",
    "        for j in range(100):\n",
    "            query, neg = neg_file.readline().split()\n",
    "            candidates.append(neg)\n",
    "            queries.append(query)\n",
    "            labels.append(0)\n",
    "#         assert(len(set(queries)) == 1)\n",
    "#         assert(len(candidates)==len(labels))\n",
    "#         assert(labels[0]==1)\n",
    "#         assert(sum(labels[1:])==0)\n",
    "#         assert(candidates[0]==pos)\n",
    "        eval_id_instances.append((query, candidates, labels))\n",
    "        i +=1\n",
    "        if (test_subset is not None) and i > test_subset:\n",
    "            break\n",
    "    return eval_id_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_word_embeddings(word_embeddings_file):\n",
    "    #word_to_vec = {}\n",
    "    print('reading word embedding file', word_embeddings_file)\n",
    "    word_to_idx = {}\n",
    "    embeddings = []\n",
    "    for i, line in enumerate(open(word_embeddings_file)):\n",
    "        split_line = line.split()\n",
    "        word, vector = split_line[0], split_line[1:]\n",
    "        vector = np.array([float(x) for x in vector])\n",
    "        #word_to_vec[word] = vector\n",
    "        word_to_idx[word] = i\n",
    "        embeddings.append(vector)\n",
    "    # last vector might not be full length\n",
    "    if len(vector) < len(embeddings[0]):\n",
    "        embeddings.pop()\n",
    "        del word_to_idx[word]\n",
    "    # add one for padding\n",
    "    embeddings.append(np.zeros(len(embeddings[0])))\n",
    "    embeddings = np.array(embeddings)\n",
    "    padding_idx = embeddings.shape[0] - 1\n",
    "    return word_to_idx, embeddings, padding_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_tokenized, word_to_idx, padding_idx, truncate):\n",
    "        # text_tokenized: Either a string representing the filename of text_tokenized, OR\n",
    "        #                 a precomputed id_to_question dictionary\n",
    "        self.truncate = truncate\n",
    "        if type(text_tokenized)==str:\n",
    "            self.id_to_question = read_text_tokenized(text_tokenized, truncate_length=self.truncate)\n",
    "        elif type(text_tokenized)==dict:\n",
    "            self.id_to_question = text_tokenized\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.padding_idx = padding_idx\n",
    "        #self.num_features = len(word_to_vec['.'])\n",
    "    \n",
    "    def get_sentence_matrix_embedding(self, words, num_words=100):\n",
    "        # returns [num_words] np matrix\n",
    "        # matrix may be padded\n",
    "        sentence_mat = np.ones(num_words) * self.padding_idx\n",
    "        i = 0\n",
    "        mask = np.zeros(num_words)\n",
    "        for word in words:\n",
    "            # TODO: IS JUST SKIPPING THE WORD THE RIGHT APPROACH?\n",
    "            if word in self.word_to_idx:\n",
    "                sentence_mat[i] = self.word_to_idx[word]\n",
    "            mask[i] = 1\n",
    "            i += 1\n",
    "            if i == num_words:\n",
    "                break\n",
    "        assert(sum(mask)>0), word\n",
    "        return sentence_mat, mask\n",
    "\n",
    "    def get_question_embedding(self, title_body_tuple):\n",
    "        title_embedding, title_mask = self.get_sentence_matrix_embedding(title_body_tuple[0], self.truncate)\n",
    "        body_embedding, body_mask = self.get_sentence_matrix_embedding(title_body_tuple[1], self.truncate)\n",
    "        return Tensor(title_embedding), Tensor(body_embedding), Tensor(title_mask), Tensor(body_mask)\n",
    "    \n",
    "    def get_question_embeddings(self, title_body_tuples):\n",
    "        num_questions = len(title_body_tuples)\n",
    "        title_embeddings = np.zeros((num_questions, self.truncate))\n",
    "        body_embeddings = np.zeros((num_questions, self.truncate))\n",
    "        title_masks = np.zeros((num_questions, self.truncate))\n",
    "        body_masks = np.zeros((num_questions, self.truncate))\n",
    "        for i, (title, body) in enumerate(title_body_tuples):\n",
    "            title_embedding, title_mask = self.get_sentence_matrix_embedding(title, self.truncate)\n",
    "            body_embedding, body_mask = self.get_sentence_matrix_embedding(body, self.truncate)\n",
    "            title_embeddings[i] = title_embedding\n",
    "            body_embeddings[i] = body_embedding\n",
    "            title_masks[i] = title_mask\n",
    "            body_masks[i] = body_mask\n",
    "        return Tensor(title_embeddings), Tensor(body_embeddings), Tensor(title_masks), Tensor(body_masks)\n",
    "    \n",
    "    def get_q_candidate_dict(self, q_id, candidate_ids):\n",
    "        q = self.id_to_question[q_id]\n",
    "        candidates = [self.id_to_question[id_] for id_ in candidate_ids]\n",
    "        q_title_embedding, q_body_embedding, q_title_mask, q_body_mask = self.get_question_embedding(q)\n",
    "        (candidate_title_embeddings, candidate_body_embeddings, \n",
    "         candidate_title_masks, candidate_body_masks) = self.get_question_embeddings(candidates)\n",
    "        # candidate_*_embeddings is tensor of [num_cands x truncate_length]\n",
    "        # q_*_embedding is tensor of [truncate_length]\n",
    "        return dict(q_body=q_body_embedding.long(), q_title=q_title_embedding.long(),\n",
    "            candidate_bodies=candidate_body_embeddings.long(), candidate_titles=candidate_title_embeddings.long(), \n",
    "            q_body_mask = q_body_mask, q_title_mask=q_title_mask, \n",
    "            candidate_body_masks=candidate_body_masks, candidate_title_masks=candidate_title_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainQuestionDataset(QuestionDataset):\n",
    "    def __init__(self, text_tokenized_file, train_file, word_to_idx, padding_idx, truncate=100, test_subset=None):\n",
    "        # test_subset: An integer representing the max number of training entries to consider.\n",
    "        #              Used for quick debugging on a smaller subset of all training data.\n",
    "        self.train_id_instances = read_train_ids(train_file, test_subset)\n",
    "        QuestionDataset.__init__(self, text_tokenized_file, word_to_idx, padding_idx, truncate)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.train_id_instances)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        (q_id, positive_id, negative_ids) = self.train_id_instances[index]\n",
    "        negative_ids_sample = random.sample(negative_ids, 20)  # sample 20 random negatives\n",
    "        candidate_ids = [positive_id]+negative_ids_sample\n",
    "        return self.get_q_candidate_dict(q_id, candidate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalQuestionDataset(QuestionDataset):\n",
    "    def __init__(self, text_tokenized, eval_file, word_to_idx, padding_idx, truncate=100, test_subset=None):\n",
    "        # test_subset: An integer representing the max number of entries to consider.\n",
    "        #              Used for quick debugging on a smaller subset of all eval data.\n",
    "        # text_tokenized: Either a string representing the filename of text_tokenized, OR\n",
    "        #                 a precomputed id_to_question dictionary\n",
    "        self.eval_id_instances = read_ubuntu_eval_ids(eval_file, test_subset)\n",
    "        QuestionDataset.__init__(self, text_tokenized, word_to_idx, padding_idx, truncate)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.eval_id_instances)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        (q_id, candidate_ids, labels, bm25scores) = self.eval_id_instances[index]\n",
    "        item = self.get_q_candidate_dict(q_id, candidate_ids)\n",
    "        item['labels'] = Tensor(labels)\n",
    "        item['bm25scores'] = Tensor(bm25scores)\n",
    "        return item    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AndroidEvalQuestionDataset(QuestionDataset):\n",
    "    # Same idea as UbuntuEval, only difference is text_tokenized corpus file will be different, and\n",
    "    # no bm25scores. Not that we're using bm25 for UbuntuEval anyways.\n",
    "    def __init__(self, text_tokenized, eval_pos_file, eval_neg_file, word_to_idx, padding_idx, truncate=100, test_subset=None, num_negs=None):\n",
    "        self.eval_id_instances = read_android_eval_ids(eval_pos_file, eval_neg_file, test_subset)\n",
    "        QuestionDataset.__init__(self, text_tokenized, word_to_idx, padding_idx, truncate)\n",
    "        self.num_negs = num_negs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.eval_id_instances)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        (q_id, candidate_ids, labels) = self.eval_id_instances[index]\n",
    "        pos_id = candidate_ids[0]\n",
    "        pos_label = labels[0]\n",
    "        if self.num_negs is None:\n",
    "            negative_ids = candidate_ids[1:]\n",
    "        else:\n",
    "            negative_ids = random.sample(candidate_ids[1:], self.num_negs)\n",
    "        candidate_ids = [pos_id] + negative_ids\n",
    "        candidate_labels = [1] + [0]*self.num_negs\n",
    "        item = self.get_q_candidate_dict(q_id, candidate_ids)\n",
    "        item['labels'] = Tensor(labels)\n",
    "        return item    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AndroidQuestionCorpusDataset(QuestionDataset):\n",
    "    # Dataset where each data item is (question_title, question_body)\n",
    "    def __init__(self, text_tokenized, word_to_idx, padding_idx, truncate=100, test_subset=22840):\n",
    "        QuestionDataset.__init__(self, text_tokenized, word_to_idx, padding_idx, truncate)\n",
    "        self.corpus = []\n",
    "        i = 0\n",
    "        for id_ in self.id_to_question:\n",
    "            self.corpus.append(self.id_to_question[id_])\n",
    "            i += 1\n",
    "            if i > test_subset:\n",
    "                break\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        q = self.corpus[index]\n",
    "        q_title_embedding, q_body_embedding, q_title_mask, q_body_mask = self.get_question_embedding(q)\n",
    "        return dict(q_body=q_body_embedding.long(), q_title=q_title_embedding.long(),\n",
    "            q_body_mask = q_body_mask, q_title_mask=q_title_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferTrainQuestionDataset(torch.utils.data.Dataset):\n",
    "    # Contains all the ubuntu dataset objects, plus a label of 'isUbuntu' sort of thing\n",
    "    # Also all the android dataset objects\n",
    "    def __init__(self, android_corpus, ubuntu_corpus, ubuntu_train_file, word_to_idx, padding_idx, truncate=100, test_subset=None):\n",
    "        # Construct a mixed dataset\n",
    "        # Where dataset[i = 0 to n_ubuntu-1] is ubuntu[i], and\n",
    "        #       dataset[i = n_ubuntu to n_ubuntu+n_android-1] is android[i-n_ubuntu]\n",
    "        self.truncate = truncate\n",
    "        self.ubuntu_dataset = TrainQuestionDataset(ubuntu_corpus, ubuntu_train_file, word_to_idx, padding_idx, truncate=truncate, test_subset=test_subset)\n",
    "        self.android_dataset = AndroidQuestionCorpusDataset(android_corpus, word_to_idx, padding_idx, truncate=truncate, test_subset=test_subset)\n",
    "        self.n_ubuntu = len(self.ubuntu_dataset)\n",
    "        self.n_android = len(self.android_dataset)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_ubuntu + self.n_android\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if index < self.n_ubuntu:\n",
    "            # return ubuntu instance\n",
    "            item = self.ubuntu_dataset[index]\n",
    "            item['isUbuntu'] = 1\n",
    "        else:\n",
    "            item = self.android_dataset[index - self.n_ubuntu]\n",
    "            item['isUbuntu'] = 0\n",
    "            # create dummy items to get batches in data_loader to play nice\n",
    "            item['candidate_bodies'] = torch.zeros(21, self.truncate).long()\n",
    "            item['candidate_titles'] = torch.zeros(21, self.truncate).long()\n",
    "            item['candidate_body_masks'] = torch.zeros(21, self.truncate)\n",
    "            item['candidate_title_masks'] = torch.zeros(21, self.truncate)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD_EMBEDDINGS_FILE = 'askubuntu/vector/vectors_pruned.200.txt'\n",
    "# UBUNTU_TEXT_TOKENIZED_FILE = 'askubuntu/text_tokenized.txt'\n",
    "# UBUNTU_TRAIN_FILE = 'askubuntu/train_random.txt'\n",
    "# UBUNTU_DEV_FILE = 'askubuntu/dev.txt'\n",
    "# UBUNTU_TEST_FILE = 'askubuntu/test.txt'\n",
    "\n",
    "# ANDROID_DEV_NEG_FILE = 'Android/dev.neg.txt'\n",
    "# ANDROID_DEV_POS_FILE = 'Android/dev.pos.txt'\n",
    "# ANDROID_TEST_NEG_FILE = 'Android/test.neg.txt'\n",
    "# ANDROID_TEST_POS_FILE = 'Android/test.pos.txt'\n",
    "# ANDROID_TEXT_TOKENIZED_FILE = 'Android/corpus.tsv'\n",
    "\n",
    "# TRUNCATE_LENGTH = 100\n",
    "# word_to_idx, embeddings, padding_idx = read_word_embeddings(WORD_EMBEDDINGS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For doing ubuntu training alone (I.E. Part 1)\n",
    "# ubuntu_train_dataset = TrainQuestionDataset(UBUNTU_TEXT_TOKENIZED_FILE, UBUNTU_TRAIN_FILE, word_to_idx, padding_idx, truncate=TRUNCATE_LENGTH)\n",
    "# ubuntu_dev_dataset = EvalQuestionDataset(ubuntu_train_dataset.id_to_question, UBUNTU_DEV_FILE, word_to_idx, padding_idx, truncate=TRUNCATE_LENGTH, test_subset=1000)\n",
    "# ubuntu_test_dataset = EvalQuestionDataset(ubuntu_train_dataset.id_to_question, UBUNTU_TEST_FILE, word_to_idx, padding_idx, truncate=TRUNCATE_LENGTH, test_subset=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For doing android eval alone (I.E. Part 2a - baselines)\n",
    "# android_dev_dataset = AndroidEvalQuestionDataset(ANDROID_TEXT_TOKENIZED_FILE, ANDROID_DEV_POS_FILE, ANDROID_DEV_NEG_FILE, \n",
    "#                                                  word_to_idx, padding_idx, truncate=100, test_subset=None)\n",
    "# android_test_dataset = AndroidEvalQuestionDataset(android_dev_dataset.id_to_question, ANDROID_TEST_POS_FILE, ANDROID_TEST_NEG_FILE, \n",
    "#                                                  word_to_idx, padding_idx, truncate=100, test_subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For doing domain adaptation (I.E. Part2b)\n",
    "# id_to_question = transfer_train_dataset.android_dataset.id_to_question\n",
    "# transfer_train_dataset = TransferTrainQuestionDataset(id_to_question, UBUNTU_TEXT_TOKENIZED_FILE, \n",
    "#                                                       UBUNTU_TRAIN_FILE, word_to_idx, padding_idx, truncate=100, test_subset=None)\n",
    "# android_dev_dataset = AndroidEvalQuestionDataset(transfer_train_dataset.android_dataset.id_to_question, ANDROID_DEV_POS_FILE, ANDROID_DEV_NEG_FILE, \n",
    "#                                                  word_to_idx, padding_idx, truncate=100, test_subset=None)\n",
    "# android_test_dataset = AndroidEvalQuestionDataset(android_dev_dataset.id_to_question, ANDROID_DEV_POS_FILE, ANDROID_DEV_NEG_FILE, \n",
    "#                                                  word_to_idx, padding_idx, truncate=100, test_subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
