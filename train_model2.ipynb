{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 2 stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "jupyter nbconvert --to script read_input.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import read_input\n",
    "from read_input import TransferTrainQuestionDataset, AndroidEvalQuestionDataset, read_word_embeddings\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from evaluation import Evaluation\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from meter_auc import AUCMeter\n",
    "\n",
    "from models import LSTM, CNN, evaluate, DomainClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def masked_select_rows(matrix, mask, mask_value=1):\n",
    "    # matrix is 2d tensor [n x m] (or variable containing 2d tensor)\n",
    "    # mask is 1d tensor\n",
    "    # returns matrix [new_n x m], with all the rows selected where mask=mask_value\n",
    "    return matrix[torch.nonzero(mask==mask_value).view(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_eval_epoch(dataset, model, batch_size, save_path):\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                              shuffle=True, drop_last=True)\n",
    "    meter = AUCMeter()\n",
    "\n",
    "    model.eval()\n",
    "    for batch in tqdm(data_loader):\n",
    "\n",
    "        # For evaluation:\n",
    "        #    - Batch is only android eval examples\n",
    "        #    - Examples have q_body, q_title, q_body_mask, q_title_mask, candidate_bodies, \n",
    "        #      candidate_titles, candidate_body_masks, candidate_title_masks, \n",
    "        #             AND label\n",
    "        \n",
    "        q_body = Variable(batch[\"q_body\"]) # batch_size x truncate_length\n",
    "        q_title = Variable(batch[\"q_title\"])\n",
    "        q_body_mask = Variable(batch[\"q_body_mask\"]) # batch_size x truncate_length\n",
    "        q_title_mask = Variable(batch[\"q_title_mask\"])\n",
    "        cand_bodies = Variable(batch[\"candidate_bodies\"]) # batch_size x num_cands x truncate_length\n",
    "        cand_titles = Variable(batch[\"candidate_titles\"])\n",
    "        cand_body_masks = Variable(batch[\"candidate_body_masks\"]) # batch_size x num_cands x truncate_length\n",
    "        cand_title_masks = Variable(batch[\"candidate_title_masks\"])\n",
    "        num_cands = cand_titles.size()[1]\n",
    "\n",
    "        q_body_enc, q_title_enc = model(q_body, q_body_mask), model(q_title, q_title_mask) # output is batch_size  x enc_length\n",
    "        cand_body_encs = model(cand_bodies.view(batch_size*num_cands, TRUNCATE_LENGTH), # output is (batch_size x num_cands) x enc_length\n",
    "                               cand_body_masks.view(batch_size*num_cands, TRUNCATE_LENGTH)) \n",
    "        cand_title_encs = model(cand_titles.view(batch_size*num_cands, TRUNCATE_LENGTH),\n",
    "                                cand_title_masks.view(batch_size*num_cands, TRUNCATE_LENGTH))\n",
    "        q_enc = q_title_enc + q_body_enc / 2.0\n",
    "        candidate_encs = cand_title_encs + cand_body_encs / 2.0\n",
    "        \n",
    "        candidate_encs = candidate_encs.view(batch_size, num_cands, -1) # batch_size x num_cands x enc_length\n",
    "        query_encs = q_enc.view(batch_size, 1, -1).expand_as(candidate_encs) # batch_size x (num_cands) x enc_length\n",
    "        cos = torch.nn.CosineSimilarity(dim=2, eps=1e-08)(candidate_encs, query_encs) # batch_size x (num_cands)\n",
    "            \n",
    "        labels = batch[\"labels\"]\n",
    "        meter.add(cos.data.view(-1), labels.view(-1))\n",
    "    \n",
    "    return meter.value(), meter.value(0.05) #return auc and auc(.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_train_epoch(dataset, encoder_model, domain_model, encoder_optimizer, domain_optimizer, batch_size, margin, _lambda, save_path):\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                              shuffle=True, drop_last=True)\n",
    "    similarity_losses = []\n",
    "    domain_pred_losses = []\n",
    "    encoder_model.train()\n",
    "    domain_model.train()\n",
    "    \n",
    "    for batch in tqdm(data_loader):\n",
    "        # For training: \n",
    "        #    Batch is mixed android and ubuntu examples\n",
    "        #    All examples have a binary isUbuntu label, and the usual q_body, q_title, q_body_mask, q_title_mask\n",
    "        #    For Android examples, the candidate_bodies, candidate_titles, candidate_body_masks, candidate_title_masks\n",
    "        #      are all just tensors of all 0s, and SHOULD NOT BE USED!!! \n",
    "        \n",
    "        q_body = Variable(batch[\"q_body\"]) # batch_size x truncate_length\n",
    "        q_title = Variable(batch[\"q_title\"])\n",
    "        q_body_mask = Variable(batch[\"q_body_mask\"]) # batch_size x truncate_length\n",
    "        q_title_mask = Variable(batch[\"q_title_mask\"])\n",
    "        ubuntu_cand_bodies = Variable(masked_select_rows(batch[\"candidate_bodies\"], batch[\"isUbuntu\"])) # num_ubuntu x num_cands x truncate_length\n",
    "        ubuntu_cand_titles = Variable(masked_select_rows(batch[\"candidate_titles\"], batch[\"isUbuntu\"]))\n",
    "        ubuntu_cand_body_masks = Variable(masked_select_rows(batch[\"candidate_body_masks\"], batch[\"isUbuntu\"])) # num_ubuntu x num_cands x truncate_length\n",
    "        ubuntu_cand_title_masks = Variable(masked_select_rows(batch[\"candidate_title_masks\"], batch[\"isUbuntu\"]))\n",
    "        num_ubuntu, num_cands = ubuntu_cand_titles.size()[0], ubuntu_cand_titles.size()[1]\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        domain_optimizer.zero_grad()\n",
    "        q_body_enc, q_title_enc = encoder_model(q_body, q_body_mask), encoder_model(q_title, q_title_mask) # output is batch_size  x enc_length\n",
    "        ubuntu_cand_body_encs = encoder_model(ubuntu_cand_bodies.view(num_ubuntu*num_cands, TRUNCATE_LENGTH), # output is (num_ubuntu x num_cands) x enc_length\n",
    "                               ubuntu_cand_body_masks.view(num_ubuntu*num_cands, TRUNCATE_LENGTH)) \n",
    "        ubuntu_cand_title_encs = encoder_model(ubuntu_cand_titles.view(num_ubuntu*num_cands, TRUNCATE_LENGTH),\n",
    "                                ubuntu_cand_title_masks.view(num_ubuntu*num_cands, TRUNCATE_LENGTH))\n",
    "        q_enc = q_title_enc + q_body_enc / 2.0\n",
    "        ubuntu_cand_encs = ubuntu_cand_title_encs + ubuntu_cand_body_encs / 2.0\n",
    "    \n",
    "        q_domain_pred = domain_model(q_enc)\n",
    "        # do we also pass in the candidate stuff into the domain classifier? All of those will be ubuntu\n",
    "        \n",
    "        ubuntu_candidate_encs = ubuntu_cand_encs.view(num_ubuntu, num_cands, -1) # num_ubuntu x num_cands x enc_length\n",
    "        ubuntu_q_enc = masked_select_rows(q_enc, batch[\"isUbuntu\"])\n",
    "        ubuntu_query_encs = ubuntu_q_enc.view(num_ubuntu, 1, -1).expand_as(ubuntu_candidate_encs) # num_ubuntu x (num_cands) x enc_length\n",
    "        cos = torch.nn.CosineSimilarity(dim=2, eps=1e-08)(ubuntu_candidate_encs, ubuntu_query_encs) # num_ubuntu x (num_cands)\n",
    "    \n",
    "\n",
    "    ######################### CALCULATE LOSSES AND UPDATE #############################\n",
    "        # is this right?????\n",
    "        target = Variable(torch.zeros(num_ubuntu).long())\n",
    "        similarity_training_loss = torch.nn.MultiMarginLoss(margin=margin)(cos, target)\n",
    "        domain_pred_loss = torch.nn.CrossEntropyLoss()(q_domain_pred, Variable(batch[\"isUbuntu\"]))\n",
    "        total_encoder_loss = similarity_training_loss - _lambda*domain_pred_loss\n",
    "\n",
    "        similarity_training_loss.backward(retain_graph=False)\n",
    "        domain_pred_loss.backward(retain_graph=False)\n",
    "        encoder_optimizer.step()\n",
    "        domain_optimizer.step()\n",
    "\n",
    "        similarity_losses.append(similarity_training_loss.data[0])\n",
    "        domain_pred_losses.append(domain_pred_loss.data[0])\n",
    "        ###########################################################################\n",
    "    if save_path is not None:\n",
    "        torch.save(encoder_model.state_dict(), save_path)\n",
    "    avg_similarity_loss = np.mean(similarity_losses)\n",
    "    avg_domain_loss = np.mean(domain_pred_losses)\n",
    "    return avg_similarity_loss, avg_domain_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_data, dev_data, test_data, encoder_model, domain_model, save_dir=None, batch_size=50, \n",
    "                margin=0.2, _lambda=1e-3, num_epochs=50, lr=1.0):\n",
    "    if (save_dir is not None) and (not os.path.exists(save_dir)):\n",
    "        os.makedirs(save_dir)\n",
    "    print(\"start train_model\")\n",
    "    print(\"****************************************\")\n",
    "    print(\"Batch size: {}, margin: {}, num_epochs: {}, lr: {}\".format(batch_size, margin, num_epochs, lr))\n",
    "    print(\"Encoder Model\", encoder_model)\n",
    "    print(\"Domain classifier model\", domain_model)\n",
    "    print(\"*****************************************\")\n",
    "    encoder_parameters = filter(lambda p: p.requires_grad, encoder_model.parameters())\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_parameters, lr=lr)\n",
    "    domain_optimizer = torch.optim.Adam(domain_model.parameters(), lr=lr)\n",
    "    \n",
    "    result_table = PrettyTable([\"Epoch\", \"train similarity loss\", \"train domain pred loss\", \n",
    "                                \"dev auc\", \"dev auc(0.05)\", \"test auc\", \"test auc(0.05)\"])\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(\"epoch\", epoch)\n",
    "        if save_dir is None:\n",
    "            save_path = None\n",
    "        else:\n",
    "            save_path = os.path.join(save_dir, 'epoch{}.pkl'.format(epoch))\n",
    "\n",
    "        similarity_loss, domain_loss = run_train_epoch(train_data, encoder_model, domain_model, encoder_optimizer, \n",
    "                                                       domain_optimizer, batch_size, margin, _lambda, save_path)\n",
    "        dev_auc, dev_auc05 = run_eval_epoch(dev_data, encoder_model, batch_size, save_path)\n",
    "        test_auc, test_auc05 = run_eval_epoch(test_data, encoder_model, batch_size, save_path)\n",
    "        result_table.add_row(\n",
    "                            [ epoch ] +\n",
    "                            [ \"%.3f\" % x for x in [similarity_loss, domain_loss] + [ dev_auc, dev_auc05 ] +\n",
    "                                        [ test_auc, test_auc05 ] ])\n",
    "        print(\"{}\".format(result_table))\n",
    "        sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD_EMBEDDINGS_FILE = 'vectors_stackexchange.txt'\n",
    "UBUNTU_TEXT_TOKENIZED_FILE = 'askubuntu/text_tokenized.txt'\n",
    "UBUNTU_TRAIN_FILE = 'askubuntu/train_random.txt'\n",
    "UBUNTU_DEV_FILE = 'askubuntu/dev.txt'\n",
    "UBUNTU_TEST_FILE = 'askubuntu/test.txt'\n",
    "\n",
    "ANDROID_DEV_NEG_FILE = 'Android/dev.neg.txt'\n",
    "ANDROID_DEV_POS_FILE = 'Android/dev.pos.txt'\n",
    "ANDROID_TEST_NEG_FILE = 'Android/test.neg.txt'\n",
    "ANDROID_TEST_POS_FILE = 'Android/test.pos.txt'\n",
    "ANDROID_TEXT_TOKENIZED_FILE = 'Android/corpus.tsv'\n",
    "\n",
    "TRUNCATE_LENGTH = 100\n",
    "word_to_idx, embeddings, padding_idx = read_word_embeddings(WORD_EMBEDDINGS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For doing domain adaptation (I.E. Part2b)\n",
    "transfer_train_dataset = TransferTrainQuestionDataset(ANDROID_TEXT_TOKENIZED_FILE, UBUNTU_TEXT_TOKENIZED_FILE, \n",
    "                                                      UBUNTU_TRAIN_FILE, word_to_idx, padding_idx, \n",
    "                                                      truncate=100, test_subset=None)\n",
    "android_dev_dataset = AndroidEvalQuestionDataset(transfer_train_dataset.android_dataset.id_to_question, \n",
    "                                                 ANDROID_DEV_POS_FILE, ANDROID_DEV_NEG_FILE, \n",
    "                                                 word_to_idx, padding_idx, truncate=100, test_subset=None)\n",
    "android_test_dataset = AndroidEvalQuestionDataset(android_dev_dataset.id_to_question, ANDROID_DEV_POS_FILE, \n",
    "                                                  ANDROID_DEV_NEG_FILE, \n",
    "                                                 word_to_idx, padding_idx, truncate=100, test_subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20 # Normally use 16\n",
    "NUM_EPOCHS = 50 # Normally use 50, but can stop early at 20\n",
    "MARGINS = [0.2, 0.4, 0.6] # Some student on piazza said 0.2 worked really well\n",
    "MARGIN = 0.2\n",
    "LRS = [1e-3, 3e-4] # Taken from paper\n",
    "LR = 1e-3\n",
    "LAMBDA = 1e-5\n",
    "SAVE_DIR = 'domain_saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DROPOUT = 0.1\n",
    "BIDIRECTIONAL = False\n",
    "ENCODING_LENGTH = 240\n",
    "encoder_model = LSTM(embeddings, padding_idx, ENCODING_LENGTH, 1, TRUNCATE_LENGTH, DROPOUT, BIDIRECTIONAL)\n",
    "\n",
    "HIDDEN_DIM_1 = 300\n",
    "HIDDEN_DIM_2 = 150\n",
    "domain_model = DomainClassifier(ENCODING_LENGTH, HIDDEN_DIM_1, HIDDEN_DIM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model(transfer_train_dataset, android_dev_dataset, android_test_dataset, \n",
    "            encoder_model, domain_model, \n",
    "            save_dir=SAVE_DIR, batch_size=BATCH_SIZE, margin=MARGIN, _lambda=LAMBDA, num_epochs=NUM_EPOCHS, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
