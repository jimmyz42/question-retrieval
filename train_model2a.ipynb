{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_input\n",
    "from read_input import read_word_embeddings, AndroidEvalQuestionDataset\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from evaluation import Evaluation\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from meter_auc import AUCMeter\n",
    "from models import LSTM, CNN, evaluate, DomainClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_encoder(sentences, masks):\n",
    "    # sentence is a tensor of batch_size x truncate_length\n",
    "    batch_size = sentences.size()[0]\n",
    "    vocab_size = padding_idx\n",
    "    word_freqs = np.zeros((batch_size, vocab_size))\n",
    "    for i in range(batch_size):        \n",
    "        for word_idx in sentences[i][masks[i].byte()]:\n",
    "            if word_idx != padding_idx:\n",
    "                word_freqs[i][word_idx] += 1\n",
    "    tfidf = transformer.fit_transform(word_freqs)\n",
    "    sys.stdout.flush()\n",
    "    return torch.Tensor(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasnan(var): \n",
    "    return np.isnan(np.sum(var.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataset, model, batch_size):\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, drop_last=True)\n",
    "    all_ranked_labels = []\n",
    "    meter = AUCMeter()\n",
    "    for batch in tqdm(data_loader):\n",
    "        q_body = batch[\"q_body\"] # batch_size x truncate_length\n",
    "        cand_bodies = batch[\"candidate_bodies\"] # batch_size x num_cands x truncate_length\n",
    "        q_title = batch[\"q_title\"]\n",
    "        cand_titles = batch[\"candidate_titles\"]\n",
    "        q_body_mask = batch[\"q_body_mask\"] # batch_size x truncate_length\n",
    "        q_title_mask = batch[\"q_title_mask\"]\n",
    "        cand_body_masks = batch[\"candidate_body_masks\"] # batch_size x num_cands x truncate_length\n",
    "        cand_title_masks = batch[\"candidate_title_masks\"]\n",
    "        num_cands = cand_titles.size()[1]\n",
    "       \n",
    "        q_body_enc, q_title_enc = model(q_body, q_body_mask), model(q_title, q_title_mask) # output is batch_size  x enc_length\n",
    "        cand_body_encs = model(cand_bodies.view(batch_size*num_cands, TRUNCATE_LENGTH), # output is (batch_size x num_cands) x enc_length\n",
    "                               cand_body_masks.view(batch_size*num_cands, TRUNCATE_LENGTH)) \n",
    "        cand_title_encs = model(cand_titles.view(batch_size*num_cands, TRUNCATE_LENGTH),\n",
    "                                cand_title_masks.view(batch_size*num_cands, TRUNCATE_LENGTH))\n",
    "        q_enc = q_title_enc + q_body_enc / 2.0\n",
    "        candidate_encs = cand_title_encs + cand_body_encs / 2.0\n",
    "        enc_length = q_enc.size()[-1]\n",
    "        \n",
    "        candidate_encs = candidate_encs.view(batch_size, num_cands, -1) # batch_size x num_cands x enc_length\n",
    "        query_encs = q_enc.view(batch_size, 1, -1).expand_as(candidate_encs) # batch_size x (num_cands) x enc_length\n",
    "        cos = torch.nn.CosineSimilarity(dim=2, eps=1e-08)(candidate_encs, query_encs) # batch_size x (num_cands)\n",
    "        labels = batch[\"labels\"]\n",
    "        meter.add(cos.view(-1, 1), labels.view(-1, 1))\n",
    "        \n",
    "    return meter.value(), meter.value(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_EMBEDDINGS_FILE = 'askubuntu/vector/vectors_pruned.200.txt'\n",
    "WORD_EMBEDDINGS_FILE = 'vectors_stackexchange.txt'\n",
    "ANDROID_DEV_NEG_FILE = 'Android/dev.neg.txt'\n",
    "ANDROID_DEV_POS_FILE = 'Android/dev.pos.txt'\n",
    "ANDROID_TEST_NEG_FILE = 'Android/test.neg.txt'\n",
    "ANDROID_TEST_POS_FILE = 'Android/test.pos.txt'\n",
    "ANDROID_TEXT_TOKENIZED_FILE = 'Android/corpus.tsv'\n",
    "\n",
    "TRUNCATE_LENGTH = 100\n",
    "word_to_idx, embeddings, padding_idx = read_word_embeddings(WORD_EMBEDDINGS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For doing android eval alone (I.E. Part 2a - baselines)\n",
    "android_dev_dataset = AndroidEvalQuestionDataset(ANDROID_TEXT_TOKENIZED_FILE, ANDROID_DEV_POS_FILE, ANDROID_DEV_NEG_FILE, \n",
    "                                                 word_to_idx, padding_idx, truncate=100, test_subset=None)\n",
    "android_test_dataset = AndroidEvalQuestionDataset(android_dev_dataset.id_to_question, ANDROID_TEST_POS_FILE, ANDROID_TEST_NEG_FILE, \n",
    "                                                 word_to_idx, padding_idx, truncate=100, test_subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfidf_encoder\n",
    "#model = LSTM(embeddings, padding_idx, 240, 1, TRUNCATE_LENGTH, 0.1, False)\n",
    "# Example of how to load a previously trained model\n",
    "# model.load_state_dict(torch.load('lstm_saved_models/epoch10.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "print('TFIDF BASELINE')\n",
    "dev_auc, dev_auc05 = evaluate_model(android_dev_dataset, model, batch_size)\n",
    "print('dev auc {}, dev auc05 {}'.format(dev_auc, dev_auc05))\n",
    "test_auc, test_auc05 = evaluate_model(android_dev_dataset, model, batch_size)\n",
    "print('dev auc {}, dev auc05 {}, test auc {}, test auc05 {}'.format(dev_auc, dev_auc05, test_auc, test_auc05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
